
Apache Spark (especially with Structured Streaming) doesnâ€™t process each event as it arrives (like Flink does).
Instead, it buffers events into small batches, say every 500ms, 1s, or 2s, and then processes them together.

ðŸ§  Think of it like:

"Wait for 1 second â†’ gather all the events â†’ run the logic on the whole batch."

Thatâ€™s micro-batching â€” it's faster than traditional batch jobs, but not real-time per event.


Why Micro-Batching â‰  Sub-Second Latency?
Letâ€™s say your goal is to respond within 200ms of an event happening (like a user clicking a listing).

If you use Spark with a 1-second micro-batch interval:

An event that arrives just after a batch starts will wait nearly a full second before itâ€™s even seen.

Then Spark needs a few 100ms to run its job and emit results.
